services:
  x-bft: &bft-base
    platform: linux/amd64
    user: "${USER_UID:-1001}:${USER_GID:-1001}"
    image: ghcr.io/unicitynetwork/bft-core:49d48f8fd3686aff1066d98eff2512e5fc71713c
  bft-root:
    <<: *bft-base
    volumes:
      - ./data/genesis-root:/genesis/root
      - ./data/genesis:/genesis
    healthcheck:
      test: ["CMD", "nc", "-zv", "bft-root", "8000"]
      interval: 5s
    networks:
      - default
    entrypoint: ["/busybox/sh", "-c"]
    command:
      - |
        if [ -f /genesis/root/node-info.json ] && [ -f /genesis/trust-base.json ] && [ -f /genesis/root/trust-base-signed.json ]; then
          echo "Genesis files already exist, skipping initialization."
        else
          echo "Creating root genesis..." &&
          ubft root-node init --home /genesis/root -g &&
          echo "Creating root trust base..." &&
          ubft trust-base generate --home /genesis --network-id 3 --node-info /genesis/root/node-info.json &&
          echo "Signing root trust base..." &&
          ubft trust-base sign --home /genesis/root --trust-base /genesis/trust-base.json
        fi
        echo "Starting root node..." &&
        ubft root-node run --home /genesis/root --address "/ip4/$(hostname -i)/tcp/8000" --trust-base /genesis/trust-base.json --rpc-server-address "$(hostname -i):8002" &&
        ls -l /genesis/root
        echo "Root node started successfully."

  bft-aggregator-genesis-gen:
    <<: *bft-base
    volumes:
      - ./data/genesis-root:/genesis/root
      - ./data/genesis:/genesis
    depends_on:
      bft-root:
        condition: service_healthy
    ports:
      - "11003:11003"
    networks:
      - default
    entrypoint: ["/busybox/sh", "-c"]
    command:
      - |
        if [ -f /genesis/aggregator/node-info.json ] && [ -f /genesis/shard-conf-7_0.json ]; then
          echo "Aggregator genesis and config already exist, skipping initialization."
        else
          echo "Creating aggregator genesis..." &&
          ubft shard-node init --home /genesis/aggregator --generate &&
          echo "Creating aggregator partition configuration..." &&
          ubft shard-conf generate --home /genesis --t2-timeout 5000 --network-id 3 --partition-id 7 --partition-type-id 7 --epoch-start 10 --node-info=/genesis/aggregator/node-info.json &&
          echo "Creating aggregator partition state..." &&
          ubft shard-conf genesis --home "/genesis/aggregator" --shard-conf /genesis/shard-conf-7_0.json
        fi
        chmod -R 755 /genesis/aggregator
        chmod 644 /genesis/shard-conf-7_0.json
        chmod 644 /genesis/trust-base.json
        chmod -R 755 /genesis/root
        echo "Permissions fixed."
        ls -l /genesis/aggregator &&
        ls -l /genesis/

  upload-configurations:
    image: curlimages/curl:8.13.0
    user: "${USER_UID:-1001}:${USER_GID:-1001}"
    depends_on:
      bft-root:
        condition: service_healthy
      bft-aggregator-genesis-gen:
        condition: service_completed_successfully
    restart: on-failure
    volumes:
      - ./data/genesis:/genesis
    command: |
      /bin/sh -c "
        echo Uploading aggregator configuration &&
        curl -X PUT -H 'Content-Type: application/json' -d @/genesis/shard-conf-7_0.json http://bft-root:8002/api/v1/configurations
      "

  # Shard 1 MongoDB Replica Set
  mongodb-shard1-1: &mongo-base
    image: mongo:7.0
    container_name: mongodb-shard1-1
    user: "${USER_UID:-1001}:${USER_GID:-1001}"
    volumes:
      - ./data/mongodb_shard1_data_1:/data/db
    command: ["--replSet", "rs1", "--bind_ip_all", "--noauth"]
    networks:
      - default
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 1s
      timeout: 1s
      retries: 30
  mongodb-shard1-2:
    <<: *mongo-base
    container_name: mongodb-shard1-2
    volumes:
      - ./data/mongodb_shard1_data_2:/data/db
  mongodb-shard1-3:
    <<: *mongo-base
    container_name: mongodb-shard1-3
    volumes:
      - ./data/mongodb_shard1_data_3:/data/db
  mongo-setup-shard1:
    image: mongo:7.0
    networks:
      - default
    depends_on:
      mongodb-shard1-1:
        condition: service_healthy
      mongodb-shard1-2:
        condition: service_healthy
      mongodb-shard1-3:
        condition: service_healthy
    entrypoint:
      - mongosh
      - "--host"
      - "mongodb-shard1-1:27017"
      - "--eval"
      - "try { rs.initiate({_id: 'rs1', members: [{_id: 0, host: 'mongodb-shard1-1:27017'}, {_id: 1, host: 'mongodb-shard1-2:27017'}, {_id: 2, host: 'mongodb-shard1-3:27017'}]}) } catch(e) { print('Replica set already initialized or error:', e.message) }"

  # Shard 2 MongoDB Replica Set
  mongodb-shard2-1:
    <<: *mongo-base
    command: ["--replSet", "rs2", "--bind_ip_all", "--noauth"]
    container_name: mongodb-shard2-1
    volumes:
      - ./data/mongodb_shard2_data_1:/data/db
  mongodb-shard2-2:
    <<: *mongo-base
    command: ["--replSet", "rs2", "--bind_ip_all", "--noauth"]
    container_name: mongodb-shard2-2
    volumes:
      - ./data/mongodb_shard2_data_2:/data/db
  mongodb-shard2-3:
    <<: *mongo-base
    command: ["--replSet", "rs2", "--bind_ip_all", "--noauth"]
    container_name: mongodb-shard2-3
    volumes:
      - ./data/mongodb_shard2_data_3:/data/db
  mongo-setup-shard2:
    image: mongo:7.0
    networks:
      - default
    depends_on:
      mongodb-shard2-1:
        condition: service_healthy
      mongodb-shard2-2:
        condition: service_healthy
      mongodb-shard2-3:
        condition: service_healthy
    entrypoint:
      - mongosh
      - "--host"
      - "mongodb-shard2-1:27017"
      - "--eval"
      - "try { rs.initiate({_id: 'rs2', members: [{_id: 0, host: 'mongodb-shard2-1:27017'}, {_id: 1, host: 'mongodb-shard2-2:27017'}, {_id: 2, host: 'mongodb-shard2-3:27017'}]}) } catch(e) { print('Replica set already initialized or error:', e.message) }"

  # Root MongoDB Replica Set
  mongodb-root-1:
    <<: *mongo-base
    command: ["--replSet", "rs-root", "--bind_ip_all", "--noauth"]
    container_name: mongodb-root-1
    volumes:
      - ./data/mongodb_root_data_1:/data/db
  mongodb-root-2:
    <<: *mongo-base
    command: ["--replSet", "rs-root", "--bind_ip_all", "--noauth"]
    container_name: mongodb-root-2
    volumes:
      - ./data/mongodb_root_data_2:/data/db
  mongodb-root-3:
    <<: *mongo-base
    command: ["--replSet", "rs-root", "--bind_ip_all", "--noauth"]
    container_name: mongodb-root-3
    volumes:
      - ./data/mongodb_root_data_3:/data/db
  mongo-setup-root:
    image: mongo:7.0
    networks:
      - default
    depends_on:
      mongodb-root-1:
        condition: service_healthy
      mongodb-root-2:
        condition: service_healthy
      mongodb-root-3:
        condition: service_healthy
    entrypoint:
      - mongosh
      - "--host"
      - "mongodb-root-1:27017"
      - "--eval"
      - "try { rs.initiate({_id: 'rs-root', members: [{_id: 0, host: 'mongodb-root-1:27017'}, {_id: 1, host: 'mongodb-root-2:27017'}, {_id: 2, host: 'mongodb-root-3:27017'}]}) } catch(e) { print('Replica set already initialized or error:', e.message) }"

  # Redis service for caching
  redis:
    image: redis:7-alpine
    container_name: redis
    user: "${USER_UID:-1001}:${USER_GID:-1001}"
    restart: unless-stopped
    volumes:
      - ./data/redis_data:/data
    networks:
      - default
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # HAProxy load balancer for Shard 1
  haproxy-shard1:
    image: haproxy:2.8-alpine
    container_name: haproxy-shard1
    restart: unless-stopped
    ports:
      - "3001:3000" # External port 3001 maps to internal HAProxy port 3000
    networks:
      - default
    volumes:
      - ./scripts/sharding/haproxy-shard1.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      - aggregator-shard1-1
      - aggregator-shard1-2
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://127.0.0.1:8404/stats",
        ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # HAProxy load balancer for Shard 2
  haproxy-shard2:
    image: haproxy:2.8-alpine
    container_name: haproxy-shard2
    restart: unless-stopped
    ports:
      - "3002:3000" # External port 3002 maps to internal HAProxy port 3000
    networks:
      - default
    volumes:
      - ./scripts/sharding/haproxy-shard2.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      - aggregator-shard2-1
      - aggregator-shard2-2
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://127.0.0.1:8404/stats",
        ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Aggregator Shard 1 Cluster
  aggregator-shard1-1: &aggregator-base
    build:
      context: .
      dockerfile: Dockerfile
      network: host
    container_name: aggregator-shard1-1
    restart: unless-stopped
    networks:
      - default
    volumes:
      - ./data/genesis:/app/bft-config
    depends_on:
      - mongo-setup-shard1
      - bft-aggregator-genesis-gen
      - redis
    environment: &environment-base
      MONGODB_URI: "mongodb://mongodb-shard1-1:27017,mongodb-shard1-2:27017,mongodb-shard1-3:27017/aggregator?replicaSet=rs1"
      PORT: "3000"
      HOST: "0.0.0.0"
      CONCURRENCY_LIMIT: "1000"
      ENABLE_DOCS: "true"
      ENABLE_CORS: "true"
      MONGODB_DATABASE: "aggregator"
      MONGODB_CONNECT_TIMEOUT: "10s"
      MONGODB_SERVER_SELECTION_TIMEOUT: "5s"
      DISABLE_HIGH_AVAILABILITY: "false"
      LOCK_TTL_SECONDS: "30"
      LEADER_HEARTBEAT_INTERVAL: "10s"
      LEADER_ELECTION_POLLING_INTERVAL: "5s"
      LOG_LEVEL: "debug"
      LOG_FORMAT: "json"
      LOG_ENABLE_JSON: "true"
      BATCH_LIMIT: "1000"
      BFT_ENABLED: "false"
      BFT_KEY_CONF_FILE: "/app/bft-config/aggregator/keys.json"
      BFT_SHARD_CONF_FILE: "/app/bft-config/shard-conf-7_0.json"
      BFT_TRUST_BASE_FILE: "/app/bft-config/trust-base.json"
      REDIS_HOST: "redis"
      REDIS_PORT: "6379"
      REDIS_PASSWORD: ""
      REDIS_DB: "0"
      REDIS_POOL_SIZE: "100"
      REDIS_MIN_IDLE_CONNS: "10"
      USE_REDIS_FOR_COMMITMENTS: "false"
      REDIS_FLUSH_INTERVAL: "50ms"
      REDIS_MAX_BATCH_SIZE: "2000"

      # Sharding configuration
      SHARDING_MODE: "child"
      SHARD_ID_LENGTH: 1
      SHARDING_CHILD_PARENT_RPC_ADDR: http://aggregator-root-1:3000
      SHARDING_CHILD_SHARD_ID: 3 # 0b11
      SHARDING_CHILD_ROUND_DURATION: 1s
      SHARDING_CHILD_PARENT_POLL_TIMEOUT: 5s
      SHARDING_CHILD_PARENT_POLL_INTERVAL: 100ms
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        if [ -f /app/bft-config/trust-base.json ]; then
          ROOT_NODE_ID=$$(cat /app/bft-config/trust-base.json | grep -o '"nodeId": "[^"]*"' | head -1 | cut -d'"' -f4)
          if [ -n "$$ROOT_NODE_ID" ]; then
            export BFT_BOOTSTRAP_ADDRESSES="/dns4/bft-root/tcp/8000/p2p/$$ROOT_NODE_ID"
            echo "Set BFT_BOOTSTRAP_ADDRESSES to: $$BFT_BOOTSTRAP_ADDRESSES"
          else
            echo "Warning: Could not extract nodeId from trust-base.json"
            exit 1
          fi
        else
          echo "Error: trust-base.json not found at /app/bft-config/trust-base.json"
          exit 1
        fi
        exec /app/aggregator
    healthcheck:
      test: ["CMD-SHELL", "nc -z -w2 127.0.0.1 $${PORT} || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
  aggregator-shard1-2:
    <<: *aggregator-base
    container_name: aggregator-shard1-2
    environment:
      <<: *environment-base
      MONGODB_URI: "mongodb://mongodb-shard1-1:27017,mongodb-shard1-2:27017,mongodb-shard1-3:27017/aggregator?replicaSet=rs1"
    depends_on:
      - mongo-setup-shard1
      - bft-aggregator-genesis-gen
      - redis

  # Aggregator Shard 2 Cluster
  aggregator-shard2-1:
    <<: *aggregator-base
    container_name: aggregator-shard2-1
    environment:
      <<: *environment-base
      MONGODB_URI: "mongodb://mongodb-shard2-1:27017,mongodb-shard2-2:27017,mongodb-shard2-3:27017/aggregator?replicaSet=rs2"
      SHARDING_MODE: "child"
      SHARDING_CHILD_SHARD_ID: 2 # 0b10
    depends_on:
      - mongo-setup-shard2
      - bft-aggregator-genesis-gen
      - redis
  aggregator-shard2-2:
    <<: *aggregator-base
    container_name: aggregator-shard2-2
    environment:
      <<: *environment-base
      MONGODB_URI: "mongodb://mongodb-shard2-1:27017,mongodb-shard2-2:27017,mongodb-shard2-3:27017/aggregator?replicaSet=rs2"
      SHARDING_MODE: "child"
      SHARDING_CHILD_SHARD_ID: 2 # 0b10
    depends_on:
      - mongo-setup-shard2
      - bft-aggregator-genesis-gen
      - redis

  # Aggregator Root Cluster
  # currently only 1 parent aggregator instance because if the parent aggregators are in HA setup then the child
  # aggregators must send to the LEADER of parent aggregators which is currently not implemented
  # (currently parent url is "hardcoded" in config).
  aggregator-root-1:
    <<: *aggregator-base
    container_name: aggregator-root-1
    ports:
      - "3009:3000"
    environment:
      <<: *environment-base
      MONGODB_URI: "mongodb://mongodb-root-1:27017,mongodb-root-2:27017,mongodb-root-3:27017/aggregator?replicaSet=rs-root"
      SHARDING_MODE: "parent"
      BFT_ENABLED: "true"
    depends_on:
      - mongo-setup-root
      - bft-aggregator-genesis-gen
      - redis

networks:
  default:
